\documentclass{report}

\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage[unicode=true]{hyperref}
\usepackage[style=authoryear,backend=biber]{biblatex}
\addbibresource{slides/local.bib}
\usepackage{paratype}
\setcounter{secnumdepth}{-1}

\begin{document}

\section{Лабораторная работа № 2}

\subsection{Задача}

Аналитическая задача — провести тематическое моделирование коллекции
текстов (LDA или STM), проинтерпретировать получившиеся темы,
проверить, есть ли темы, которые неравномерно распределены в двух
классах текстов, выделенных внутри коллекции (преобладают в одном из
двух классов).

Особенность этой работы состоит в том, что алгоритмам обучения
тематических моделей требуется достаточно большой объем корпуса
текстов для сходимости (т.е. для сбора достаточной статистики по
совместной встречаемости слов, чтобы выделенные темы получались
стабильными и интерпретируемыми). В широкой практике эти методы обычно
применяются к корпусам объемом от 1 млн слов и более.  Однако
формально нижний предел на объем корпуса самим алгоритмом не
ограничен, поэтому есть возможно получить небессмысленные результаты и
с меньшим объемом данных.

\subsection{Данные}

В зависимости от размера вашего корпуса (и характера данных) есть три
варианта выполнения этой работы:

\begin{enumerate}
\item[1)] Провести тематическое моделирование вашей коллекции
  текстов\footnote{Если в качестве своих данных вы используете
    датасет из интернета, то у вас проблема: нужно смещаться к
    варианту 2 или 3.}. Этот вариант стоит попробовать, если объем
  ваших данных — не менее 50—100 тыс. слов. Если тысяч 30 слов, то
  тоже можно рискнуть. Если данных еще меньше, смотрите следующие
  варианты.
\item[2)] Добавить в коллекцию для тематического моделирования фоновый
  корпус большего размера и сделать тематическую модель на
  объединенных данных: Ваши данные (из прежних лабораторных) + фоновый
  корпус.

  Требования к фоновому корпусу:
  \begin{itemize}
  \item Объем текста, который доведет общий объем ваших данных до
    минимального порога, на котором получится тематическая модель
    (см. пункт 1). Превышать объем, естественно, можно, в целом чем
    больше данных — тем лучше тематическая модель.
  \item Тексты должны быть достаточно похожи на ваши основные данные:
    они не должны быть в точности такими же, но должны быть
    сопоставимы с вашими исходными данными в тематическом
    отношении. Эту сопоставимость необходимо обосновать в отчете.
  \item В качестве фонового корпуса можно брать датасеты/текстовые
    коллекции из любых открытых источников, для этой задачи в рамках
    данной лабораторной работы не действует ограничение на повторение
    данных (в двух и более работах может использоваться один и тот же
    датасет в качестве фонового корпуса). Можно собрать фоновый корпус
    и самостоятельно.
  \end{itemize}
\item[3)] Если и данные невелики, и фоновый корпус по каким-то
  причинам не удается подобрать, можно сделать тематическую модель на
  данных, предложенных преподавателем. Набор датасетов, подходящих для
  тематического моделирования, доступен в Репозитории открытых данных
  по русской литературе и фольклору в разделе Корпуса текстов:
  \url{https://dataverse.pushdom.ru/dataverse/corpora}. Для этого
  варианта выполнения работы \textbf{нельзя} использовать свободно
  доступные в интернете коллекции, только коллекции из списка
  предложенных преподавателем.
\end{enumerate}


\subsection{Этапы работы}

\begin{enumerate}
\item Чистка и нормализация текста: принять решения, влияющие на
  результат токенизации текстов и включение слов в тематическую модель
  (нужна ли лемматизация, что включать в список стоп-слов, строить его
  статически или динамически, оставлять ли для моделирования только
  слова определенных частей речи и т.п.).
\item Выбрать способ членения корпуса на документы (следует учитывать,
  что нежелательно, когда текст документа слишком короток или слишком
  длинен (не достигает 50 или сильно превышает 1000 слов).
\item Выбрать алгоритм тематического моделирования. Это может быть LDA
  (с помощью пакета mallet или любой другой реализации этого
  алгоритма в R) или STM (пакет stm). Дальнейшие шаги выполняются с
  использованием выбранного алгоритма. Для зачета достаточно одного из
  двух алгоритмов, но если хватит времени и сил, можете сделать оба.
\item Выбор количества тем. Этот ключевой параметр модели подбирается
  таким же образом, как и у других алгоритмов машинного обучения,
  путем перебора вариантов. Постройте несколько моделей с разным
  количеством тем, посмотрите их результаты и выберите из них одну для
  дальнейшего анализа.\footnote{Количество тем должно разумно
    соотноситься с количеством слов/документов, а также возможностями
    интерпретации. В маленьких корпусах не получится хороших моделей с
    большим количеством тем, делать более нескольких сотен тем обычно
    не имеет смысла даже в огромных корпусах.} Предварительно
  оценивать качество моделей можно как с помощью специализированных
  метрик качества (см. например известный показатель coherence,
  предложенный \href{Mimno et
    al.}{https://www.aclweb.org/anthology/D11-1024.pdf}), так и следуя
  общепринятой практике, «на глаз», путем оценки связности и
  интерпретируемости топ-10/20/50 слов получившихся тем.
\item Подробный анализ одной модели с выбранным на предыдущем шаге
  количеством тем:
  \begin{itemize}
  \item Построение интерактивной визуализации для модели.
  \item Интерпретация тем: каждой теме нужно присвоить описательную
    метку либо метку из разряда «шум/нрзб/не могу
    интерпретировать». Интерпретация должна быть основана на анализе
    вошедших в тему слов (топ по FREX, слова не вошедшие в топ, но
    характерные для темы), анализе документов, в которых представлена
    данная тема, а также с учетом общего объема темы (общее количество
    отнесенных к ней слов).
  \end{itemize}
\item Тематическая характеристика каждого из двух классов текстов в
  ваших данных, основанная на темах, выделенных моделью. Для общей
  характеристики достаточно простой суммарной статистики — общая доля
  каждой темы в документах одного и другого классов.\footnote{Такая
    статистика легко вычисляется по матрице тем—документов, doc-topic
    matrix, это один из ключевых результатов работы любой тематической
    модели.}. Характеристика должна содержать обобщающее заключение о
  наличии/отсутствии различия между текстами на уровне тематики и о
  характере этого различия.

  Если работа выполняется по варианту 2 (с добавлением фонового
  корпуса), то характерные темы следует выделять только для документов
  из подкорпуса с вашими исходными данными.
\item По желанию (не обязательно для положительной оценки за
  работу) для тех тем, где доля в разных классах существенно
  отличается, можно оценить величину и статистическую надежность этого
  различия: либо включив класс документа в ковариаты (при
  использовании модели STM), либо рассчитав значимость отличия с
  помощью перестановочного теста, по методу, предложенному в статье
  \fullcite{jockers2013significant}. \url{http://maslinsky.spb.ru/courses/cmta2017/reader/jockers2013.pdf}
\end{enumerate}


\subsection{Отчет} 

Загружается на сервер в домашний каталог вашего пользователя. Отчет
должен состоять из двух файлов: lab2.Rmd и lab2.html (html-версия,
полученная с помощью knitr). Файлы будут автоматически собраны
скриптом, когда наступит дедлайн (по аналогии со сбором результатов
практических работ). \textbf{Пожалуйста, не переименовывайте
  файлы, а то скрипт их не найдет}. 

Если с загрузкой отчета на сервер возникли какие-то сложности,
допускается сдать отчет по электронной почте на адрес
kmaslinsky@hse.ru (с объяснением проблемы).

\subsubsection{Содержание отчета}

В отчете по результатам работы необходимо представить: 

\begin{enumerate}
\item Характеристику данных (принципы составления коллекции, ее объем
  в словах), принцип разбиения на классы.
\item Описание и обоснование принятых решений относительно
  нормализации и подсчета слов, разделения корпуса на документы. 
\item Описание проверенных значений количества тем, обоснование для
  выбора модели. 
\item Скриншот(ы) интерактивной визуализации одной из выбранных для
  анализа моделей. 
\item Полный список проинтерпретированных тем с метками, при
  необходимости можно дать комментарии по лексическому составу темы
  или привести пример документов с темой.
\item Тематическую характеристику каждого из двух классов, как минимум
  в виде описательного текста, желательно привести цифры по долям
  наиболее интересных тем в обоих классах (можно графики или
  таблицы). 
\item Если рассчитывались меры различия в использовании тем между
  классами, то привести их результаты.
\end{enumerate}

\subsubsection{Формат отчета}

В отчете помимо перечисленных выше содержательных моментов должны быть
представлены:

\begin{enumerate}
\item Код (весьма желательно оставить только релевантные, минимально
  необходимые для расчетов фрагменты кода, не загружая отчет полной
  историей всех успешных и неуспешных попыток).
\item Вывод результатов (таблицы топ-слов — обязательно, всякие
  графики и визуализации — добавить по вкусу).
\end{enumerate}

Отчет может быть оформлен в одном из двух форматов:
\begin{itemize}
\item[а)] в формате .Rmd, в этом случае необходимо приложить
  .html-файл с кодом, результатами и визуализацией, полученный с
  помощью knitr
\item[б)] «в разборе»: .R-скрипт с кодом (и комментариями), документ с
  текстом отчета, при необходимости приложенные файлы с результатами и
  визуализациями. В этом случае отчет сдается по электронной
  почте. Если вы работаете на MacOS, пожалуйста, либо называйте файлы
  латиницей, либо не запаковывайте их в zip-архив.
\end{itemize}


Исходные данные прикладывать к отчету \textbf{не нужно}.

\section{Критерии оценки}

\begin{itemize}
\item Полнота выполнения задания (выполнены все обязательные шаги с
  хотя бы одним из алгоритмов LDA/STM). 
\item Корректность расчетов (нет ошибок в формулах или сбоев в данных,
  которые приводят к неверным или бессмысленным результатам).
\item Полнота отчета: описаны все принятые решения, приведен код и
  результаты, все результаты прокомментированы.
\item (Повышающий коэффициент) Глубина мысли: содержательная
  постановка задачи, интересные интерпретации, тонкие наблюдения,
  остроумные комментарии и другие виньетки, украшающие нашу
  академическую жизнь.
\item Неформальным, но неизбежным фактором, влияющим на общую оценку
  работы, будет удобочитаемость отчета.
\end{itemize}

\subsection{Сроки} 

Дедлайн — \textbf{06.12.2021 23:59}. Своевременная проверка работ, сданных
после дедлайна, \textbf{не гарантируется}. 

\subsection{Материалы}

\begin{itemize}
\item Скрипт-образец, в котором продемонстрированы все этапы работы на
  примере данных по детским детективам (для LDA) и данных проекта
  Manifesto (для STM), а также способы построения интерактивной
  визуализации моделей для обоих алгоритмов:
  \url{http://maslinsky.spb.ru/courses/cmta2021/scripts/07topic_models.Rmd}
\end{itemize}

\subsection{Техподдержка}

Методологические вопросы, экзистенциальные сомнения, а также
технические проблемы давайте обсуждать в группе курса в Телеграм.

\end{document}

